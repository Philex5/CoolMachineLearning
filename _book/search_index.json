{"index":{"version":"0.5.12","fields":[{"name":"title","boost":10},{"name":"keywords","boost":15},{"name":"body","boost":1}],"ref":"url","documentStore":{"store":{"./":["introduct","个人机器学习笔记"],"Chapter1/1.MLAlgorithms.html":["第一章：线性分类模型"],"Chapter1/1.1percetron.html":["#","$$","$$\\nablawl(w,","$$b","$$min{w,b}","$$w","$${\\nabla}{w}l(w,b)","(1):","(pred_i",")","*","+",",$$n_i$$表示当前实例更新的次数，实例点更新的次数越多，代表它离超平面越近，越难正确分类。","0,","1.1","1])","=","\\eta","\\frac{w*x_0","\\leftarrow","\\rightarrow","\\subseteq","\\sum_{x_i\\subseteq","\\sum{i=1}^n","\\sum{i=1}^{n}a_iy_ix_i$$","\\sum{x_i","\\sum{x_i\\subseteq","a_i","b","b)","b)=","b)}","b)​$$的总和，参数更新利用的是梯度下降。之所以是最基础是因为不管损失函数还是参数更新的方法都很是最简单的而且也没有对分离超平面进行限制取最优。感知机算法的对偶形式是将权重向量表示为实例ｘ和标记y的组合，使用了更多的矩阵运算，在使用相同的初始参数的情况下会得到相同的结果。","b}{||w||}","b求得对应的损失函数的极小值。损失函数的梯度为：","b进行更新","def","flag","global","histori","l(w,","l(w,b","lr):","m}y_i$$","m}y_ix_i$$","m}{y_i(w*x_i","np.asarray([0,","np.dot(w,","pred_i","range(len(x)):","train(x,","true","w","x[i])","x_i","xiy_i","x可以是多维的权重向量和特征向量，一般都有多个特征，所求的也是多维的超平面。","y(w*x+b)","y,","y[i])","y_i$$","y_ix_i$$","yi","主要目标是学习一个将训练集中的正实例点和负实例点完全正确分开的分离超平面.","其中$$a_i=n_i\\eta$$","则","学习策略","学习算法","对于误分类的点,$$","对偶形式的基本想法是，将w和b表示为实例$$x_i$$和标记$$y_i$$的线性组合的形式，通过求解其系数而求得w和b.","将误分类点到分离超平面的距离作为损失函数.没有选择误分类点的数量作为损失函数，因为不好求梯度更新参数。","总结","感知机","感知机(perceptron)是最基础的线性二分类模型，输入实例的特征向量，输出实例的$$\\pm$$类别","感知机学习算法就是对以下最优化问题的算法","感知机学习算法是误分类驱动的，先随机选择一个超平面,然后使用梯度下降法不断极小化损失函数.所谓梯度下降法就是使用损失函数的梯度不断更新参数w","感知机学习算法的对偶形式","感知机并不只是二维的，w","感知机算法学习参数(权重向量和偏置)求得将正负实例分开的分离超平面。损失函数利用的是误分类点到分离超平面的函数距离$$y_i(w\\cdot","所谓对偶，我的理解是转变思路，以另一种方式解决同一问题，但结果并不会发生改变。","所谓梯度，就是每个变量的偏导数的集合，是一个向量，指的是标量场增长最快的方向，长度是最大变化率。所谓标量场，指的是空间中任意一个点的属性都可以用一个标量表示的场。","损失函数","概念与定义","用来判断是否训练完成","算法实现(python)","算法效果可视化：","算法的收敛性","输入空间$$r^{n}$$中任一点$$x_0$$到超平面s的距离:","这里||w||是w的l_2范数","选择一个误分类的点，对参数w"],"Chapter1/1.2LogisticRegression.html":["$$l(w)","$$logit(p(y=1|x))","$$logit(p)","$$loss(\\phi(z),","$$p(y=0|x)","$$p(y=1|x)","$$sigmoid","$$wj","$$其中","(1","(y^{(i)}","(z^{(i)}))^{1","(z^{(i)}))^{y^{(i)}}((1","({1,0})$$","+","1$$","1.2","1.2逻辑回归",":=","=","\\cdot","\\eta","\\frac","\\frac{1}{1","\\frac{e^{w\\cdot","\\frac{p(y=1|x)}{1","\\frac{p}{1","\\phi","\\phi(z^{(i)})))$$","\\phi(z^{(i)}))x_j$$","\\prod_{i=1}^{n}((\\phi","\\subseteq","\\sum_{i=1}^n(","\\sum{i=1}^n","b","e^{w\\cdot","log","logl(w)","p(y=1|x)}","p(y|","p}$$","regression）也称为\"对数几率回归\"，又称为\"逻辑斯谛\"回归。是一个对数线性分类模型，虽然有回归两个字，但属于分类模型而不是回归模型。","vs","w","w)","w\\cdot","w_0,x_0","w_j","x","x$$","x;","x^{(i)}$$","x}}$$","y)","y^{(i)})log(1","y^{(i)}log(\\phi(z^{(i)}))","y^{(i)}}),i","z^{(i)}=","{1}{1+e^{","}}$$","}}{1","事件的对数几率或logit函数为：","代码实现(python):","似然函数","几率(odd):","则逻辑回归的损失函数为：","参数学习","参数更新：","对于逻辑回归:","将最大化似然函数改为最小化对数似然即损失函数$loss$.(其实就是cross_entropy)","所以逻辑回归模型的本质是：输出y=1的对数几率是输入x的线性函数表示的模型。","指事件发生的概率与该事件不发生的概率之间的比值。","梯度下降法","每次更新参数使用全部样本的梯度下降更新幅度更大，但可能会收敛不到全局最优点，在最优点两边跳动，而且如果样本数量太大消耗太大；每次更新参数使用一个样本的随机梯度下降更新的频率更快，收敛得也更快，也可以跳过局部最优点，可以用于在线学习，应用得更广泛；还有一种改进的随机梯度下降是每次随机选取更新参数用的样本。","牛顿法：","线性回归","设$$\\phi()=sigmoid,","这里使用最大似然法进行参数估计，学习使得当前标记序列出现概率最大的权重向量$w$.","逻辑回归","逻辑回归是使用线性预测的结果去逼近真实标记的对数几率。这也是为什么被称为“对数几率回归”的原因。","逻辑回归模型为:","逻辑回归模型的参数学习通常采用的方法是梯度下降法和拟牛顿法","逻辑回归的优缺点","逻辑回归的参数估计","逻辑回归的定义","逻辑回归的本质","逻辑回归相当于线性预测结果经过sigmoid激活函数，得到类别概率分布。","逻辑回归（logist"],"Chapter1/1.3LDA.html":["1.3","1.3线性判别分析(linear","analysis)","decis","lda"],"Chpater2/2.DicisionTree.html":["第二章：决策树"],"Chpater3/3.NeuralNetwork.html":["第三章：神经网络"],"Chpater4/4.SVM.html":["第四章：支持向量机"],"Chpater5/5.Bayes.html":["第五章：贝叶斯分类器"],"Chpater6/6.GraphModel.html":["第六章：图模型"],"Chpater7/7.EmsembleLearning.html":["第七章：集成学习"],"Chpater8/8.UnsupervisedLearning.html":["第八章：无监督学习"],"Chpater8/8.EnhancementLearning.html":["第九章：强化学习"],"Chpater10/10.MathofML.html":["第十章：机器学习中的数学"],"Chpater11/11.TransferLearning.html":["第十一章：迁移学习"]},"length":15},"tokenStore":{"root":{"0":{"docs":{},",":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}},"1":{"docs":{},".":{"1":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":5.0078125}}},"2":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":5}},"逻":{"docs":{},"辑":{"docs":{},"回":{"docs":{},"归":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"3":{"docs":{"Chapter1/1.3LDA.html":{"ref":"Chapter1/1.3LDA.html","tf":5}},"线":{"docs":{},"性":{"docs":{},"判":{"docs":{},"别":{"docs":{},"分":{"docs":{},"析":{"docs":{},"(":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{"Chapter1/1.3LDA.html":{"ref":"Chapter1/1.3LDA.html","tf":0.3333333333333333}}}}}}}}}}}}}}}},"docs":{}},"]":{"docs":{},")":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}},"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"./":{"ref":"./","tf":10}}}}}}}}}}},"个":{"docs":{},"人":{"docs":{},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"笔":{"docs":{},"记":{"docs":{"./":{"ref":"./","tf":1}}}}}}}}}},"第":{"docs":{},"一":{"docs":{},"章":{"docs":{},"：":{"docs":{},"线":{"docs":{},"性":{"docs":{},"分":{"docs":{},"类":{"docs":{},"模":{"docs":{},"型":{"docs":{"Chapter1/1.MLAlgorithms.html":{"ref":"Chapter1/1.MLAlgorithms.html","tf":11}}}}}}}}}}},"二":{"docs":{},"章":{"docs":{},"：":{"docs":{},"决":{"docs":{},"策":{"docs":{},"树":{"docs":{"Chpater2/2.DicisionTree.html":{"ref":"Chpater2/2.DicisionTree.html","tf":11}}}}}}}},"三":{"docs":{},"章":{"docs":{},"：":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{"Chpater3/3.NeuralNetwork.html":{"ref":"Chpater3/3.NeuralNetwork.html","tf":11}}}}}}}}},"四":{"docs":{},"章":{"docs":{},"：":{"docs":{},"支":{"docs":{},"持":{"docs":{},"向":{"docs":{},"量":{"docs":{},"机":{"docs":{"Chpater4/4.SVM.html":{"ref":"Chpater4/4.SVM.html","tf":11}}}}}}}}}},"五":{"docs":{},"章":{"docs":{},"：":{"docs":{},"贝":{"docs":{},"叶":{"docs":{},"斯":{"docs":{},"分":{"docs":{},"类":{"docs":{},"器":{"docs":{"Chpater5/5.Bayes.html":{"ref":"Chpater5/5.Bayes.html","tf":11}}}}}}}}}}},"六":{"docs":{},"章":{"docs":{},"：":{"docs":{},"图":{"docs":{},"模":{"docs":{},"型":{"docs":{"Chpater6/6.GraphModel.html":{"ref":"Chpater6/6.GraphModel.html","tf":11}}}}}}}},"七":{"docs":{},"章":{"docs":{},"：":{"docs":{},"集":{"docs":{},"成":{"docs":{},"学":{"docs":{},"习":{"docs":{"Chpater7/7.EmsembleLearning.html":{"ref":"Chpater7/7.EmsembleLearning.html","tf":11}}}}}}}}},"八":{"docs":{},"章":{"docs":{},"：":{"docs":{},"无":{"docs":{},"监":{"docs":{},"督":{"docs":{},"学":{"docs":{},"习":{"docs":{"Chpater8/8.UnsupervisedLearning.html":{"ref":"Chpater8/8.UnsupervisedLearning.html","tf":11}}}}}}}}}},"九":{"docs":{},"章":{"docs":{},"：":{"docs":{},"强":{"docs":{},"化":{"docs":{},"学":{"docs":{},"习":{"docs":{"Chpater8/8.EnhancementLearning.html":{"ref":"Chpater8/8.EnhancementLearning.html","tf":11}}}}}}}}},"十":{"docs":{},"章":{"docs":{},"：":{"docs":{},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"学":{"docs":{"Chpater10/10.MathofML.html":{"ref":"Chpater10/10.MathofML.html","tf":11}}}}}}}}}}}},"一":{"docs":{},"章":{"docs":{},"：":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"学":{"docs":{},"习":{"docs":{"Chpater11/11.TransferLearning.html":{"ref":"Chpater11/11.TransferLearning.html","tf":11}}}}}}}}}}},"#":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}},"$":{"docs":{},"$":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0546875}},"\\":{"docs":{},"n":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"a":{"docs":{},"w":{"docs":{},"l":{"docs":{},"(":{"docs":{},"w":{"docs":{},",":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}},"b":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.015625}}},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"{":{"docs":{},"w":{"docs":{},",":{"docs":{},"b":{"docs":{},"}":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}},"w":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.015625}},"j":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}},"{":{"docs":{},"\\":{"docs":{},"n":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"a":{"docs":{},"}":{"docs":{},"{":{"docs":{},"w":{"docs":{},"}":{"docs":{},"l":{"docs":{},"(":{"docs":{},"w":{"docs":{},",":{"docs":{},"b":{"docs":{},")":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"(":{"docs":{},"w":{"docs":{},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"p":{"docs":{},"(":{"docs":{},"y":{"docs":{},"=":{"1":{"docs":{},"|":{"docs":{},"x":{"docs":{},")":{"docs":{},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"docs":{}}}},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}},"s":{"docs":{},"s":{"docs":{},"(":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"h":{"docs":{},"i":{"docs":{},"(":{"docs":{},"z":{"docs":{},")":{"docs":{},",":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}},"p":{"docs":{},"(":{"docs":{},"y":{"docs":{},"=":{"0":{"docs":{},"|":{"docs":{},"x":{"docs":{},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"1":{"docs":{},"|":{"docs":{},"x":{"docs":{},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"docs":{}}}}},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}},"其":{"docs":{},"中":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"(":{"1":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}},")":{"docs":{},":":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}},"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}},"y":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}},"z":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{},")":{"docs":{},"^":{"docs":{},"{":{"1":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"docs":{},"y":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},"}":{"docs":{},"(":{"docs":{},"(":{"1":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"{":{"1":{"docs":{},",":{"0":{"docs":{},"}":{"docs":{},")":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"docs":{}}},"docs":{}}},")":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}},"*":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}},"+":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0625},"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.028846153846153848}}},",":{"docs":{},"$":{"docs":{},"$":{"docs":{},"n":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"$":{"docs":{},"表":{"docs":{},"示":{"docs":{},"当":{"docs":{},"前":{"docs":{},"实":{"docs":{},"例":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"次":{"docs":{},"数":{"docs":{},"，":{"docs":{},"实":{"docs":{},"例":{"docs":{},"点":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"次":{"docs":{},"数":{"docs":{},"越":{"docs":{},"多":{"docs":{},"，":{"docs":{},"代":{"docs":{},"表":{"docs":{},"它":{"docs":{},"离":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},"越":{"docs":{},"近":{"docs":{},"，":{"docs":{},"越":{"docs":{},"难":{"docs":{},"正":{"docs":{},"确":{"docs":{},"分":{"docs":{},"类":{"docs":{},"。":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"=":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.078125},"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.11538461538461539}}},"\\":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.03125},"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}},"f":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}},"{":{"1":{"docs":{},"}":{"docs":{},"{":{"1":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"docs":{}}}},"docs":{},"w":{"docs":{},"*":{"docs":{},"x":{"docs":{},"_":{"0":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}},"docs":{}}}}},"e":{"docs":{},"^":{"docs":{},"{":{"docs":{},"w":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}},"p":{"docs":{},"(":{"docs":{},"y":{"docs":{},"=":{"1":{"docs":{},"|":{"docs":{},"x":{"docs":{},")":{"docs":{},"}":{"docs":{},"{":{"1":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"docs":{}}}}}}},"docs":{}}}},"}":{"docs":{},"{":{"1":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"docs":{}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.015625}}}}}}}}}}},"r":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.015625}}}}}}}}}}}},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"q":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125},"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}},"m":{"docs":{},"_":{"docs":{},"{":{"docs":{},"x":{"docs":{},"_":{"docs":{},"i":{"docs":{},"\\":{"docs":{},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"q":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}},"i":{"docs":{},"=":{"1":{"docs":{},"}":{"docs":{},"^":{"docs":{},"n":{"docs":{},"(":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"docs":{}}}}},"{":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},"}":{"docs":{},"^":{"docs":{},"n":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125},"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"{":{"docs":{},"n":{"docs":{},"}":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"y":{"docs":{},"_":{"docs":{},"i":{"docs":{},"x":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}},"docs":{}}},"x":{"docs":{},"_":{"docs":{},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}},"\\":{"docs":{},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"q":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.015625}}}}}}}}}}}}}}}}}},"c":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"p":{"docs":{},"h":{"docs":{},"i":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}},"(":{"docs":{},"z":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{},")":{"docs":{},")":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}},"x":{"docs":{},"_":{"docs":{},"j":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"o":{"docs":{},"d":{"docs":{},"_":{"docs":{},"{":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},"}":{"docs":{},"^":{"docs":{},"{":{"docs":{},"n":{"docs":{},"}":{"docs":{},"(":{"docs":{},"(":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"h":{"docs":{},"i":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"y":{"docs":{},"s":{"docs":{},"i":{"docs":{},"s":{"docs":{},")":{"docs":{"Chapter1/1.3LDA.html":{"ref":"Chapter1/1.3LDA.html","tf":0.3333333333333333}}}}}}}}}}},"b":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0234375},"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}},")":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}},"=":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}},"}":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.015625}}},"​":{"docs":{},"$":{"docs":{},"$":{"docs":{},"的":{"docs":{},"总":{"docs":{},"和":{"docs":{},"，":{"docs":{},"参":{"docs":{},"数":{"docs":{},"更":{"docs":{},"新":{"docs":{},"利":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"。":{"docs":{},"之":{"docs":{},"所":{"docs":{},"以":{"docs":{},"是":{"docs":{},"最":{"docs":{},"基":{"docs":{},"础":{"docs":{},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"不":{"docs":{},"管":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"还":{"docs":{},"是":{"docs":{},"参":{"docs":{},"数":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"都":{"docs":{},"很":{"docs":{},"是":{"docs":{},"最":{"docs":{},"简":{"docs":{},"单":{"docs":{},"的":{"docs":{},"而":{"docs":{},"且":{"docs":{},"也":{"docs":{},"没":{"docs":{},"有":{"docs":{},"对":{"docs":{},"分":{"docs":{},"离":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},"进":{"docs":{},"行":{"docs":{},"限":{"docs":{},"制":{"docs":{},"取":{"docs":{},"最":{"docs":{},"优":{"docs":{},"。":{"docs":{},"感":{"docs":{},"知":{"docs":{},"机":{"docs":{},"算":{"docs":{},"法":{"docs":{},"的":{"docs":{},"对":{"docs":{},"偶":{"docs":{},"形":{"docs":{},"式":{"docs":{},"是":{"docs":{},"将":{"docs":{},"权":{"docs":{},"重":{"docs":{},"向":{"docs":{},"量":{"docs":{},"表":{"docs":{},"示":{"docs":{},"为":{"docs":{},"实":{"docs":{},"例":{"docs":{},"ｘ":{"docs":{},"和":{"docs":{},"标":{"docs":{},"记":{"docs":{},"y":{"docs":{},"的":{"docs":{},"组":{"docs":{},"合":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"运":{"docs":{},"算":{"docs":{},"，":{"docs":{},"在":{"docs":{},"使":{"docs":{},"用":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"初":{"docs":{},"始":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"会":{"docs":{},"得":{"docs":{},"到":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"}":{"docs":{},"{":{"docs":{},"|":{"docs":{},"|":{"docs":{},"w":{"docs":{},"|":{"docs":{},"|":{"docs":{},"}":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}},"求":{"docs":{},"得":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"极":{"docs":{},"小":{"docs":{},"值":{"docs":{},"。":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"为":{"docs":{},"：":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}},"进":{"docs":{},"行":{"docs":{},"更":{"docs":{},"新":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}},"d":{"docs":{},"e":{"docs":{},"f":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}},"c":{"docs":{},"i":{"docs":{},"s":{"docs":{"Chapter1/1.3LDA.html":{"ref":"Chapter1/1.3LDA.html","tf":0.3333333333333333}}}}}}},"f":{"docs":{},"l":{"docs":{},"a":{"docs":{},"g":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"l":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}},"h":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}},"l":{"docs":{},"(":{"docs":{},"w":{"docs":{},",":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}},"b":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}},"r":{"docs":{},")":{"docs":{},":":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}},"o":{"docs":{},"g":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.019230769230769232}},"l":{"docs":{},"(":{"docs":{},"w":{"docs":{},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}},"d":{"docs":{},"a":{"docs":{"Chapter1/1.3LDA.html":{"ref":"Chapter1/1.3LDA.html","tf":5}}}}},"m":{"docs":{},"}":{"docs":{},"y":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}},"x":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}},"{":{"docs":{},"y":{"docs":{},"_":{"docs":{},"i":{"docs":{},"(":{"docs":{},"w":{"docs":{},"*":{"docs":{},"x":{"docs":{},"_":{"docs":{},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.015625}}}}}}}}}}}}}},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"a":{"docs":{},"s":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"(":{"docs":{},"[":{"0":{"docs":{},",":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}},"docs":{}}}}}}}}}},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{},"(":{"docs":{},"w":{"docs":{},",":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}},"(":{"docs":{},"y":{"docs":{},"=":{"1":{"docs":{},"|":{"docs":{},"x":{"docs":{},")":{"docs":{},"}":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"docs":{}},"|":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}},"}":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"e":{"docs":{},"(":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{},")":{"docs":{},":":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"）":{"docs":{},"也":{"docs":{},"称":{"docs":{},"为":{"docs":{},"\"":{"docs":{},"对":{"docs":{},"数":{"docs":{},"几":{"docs":{},"率":{"docs":{},"回":{"docs":{},"归":{"docs":{},"\"":{"docs":{},"，":{"docs":{},"又":{"docs":{},"称":{"docs":{},"为":{"docs":{},"\"":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"斯":{"docs":{},"谛":{"docs":{},"\"":{"docs":{},"回":{"docs":{},"归":{"docs":{},"。":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"对":{"docs":{},"数":{"docs":{},"线":{"docs":{},"性":{"docs":{},"分":{"docs":{},"类":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"虽":{"docs":{},"然":{"docs":{},"有":{"docs":{},"回":{"docs":{},"归":{"docs":{},"两":{"docs":{},"个":{"docs":{},"字":{"docs":{},"，":{"docs":{},"但":{"docs":{},"属":{"docs":{},"于":{"docs":{},"分":{"docs":{},"类":{"docs":{},"模":{"docs":{},"型":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"回":{"docs":{},"归":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},"x":{"docs":{},",":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}},"u":{"docs":{},"e":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}},"w":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.03125},"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"\\":{"docs":{},"c":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"_":{"0":{"docs":{},",":{"docs":{},"x":{"docs":{},"_":{"0":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"docs":{}}}}},"docs":{},"j":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}},"x":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.019230769230769232}},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},")":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}},"_":{"docs":{},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}},"i":{"docs":{},"y":{"docs":{},"_":{"docs":{},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"多":{"docs":{},"维":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"向":{"docs":{},"量":{"docs":{},"和":{"docs":{},"特":{"docs":{},"征":{"docs":{},"向":{"docs":{},"量":{"docs":{},"，":{"docs":{},"一":{"docs":{},"般":{"docs":{},"都":{"docs":{},"有":{"docs":{},"多":{"docs":{},"个":{"docs":{},"特":{"docs":{},"征":{"docs":{},"，":{"docs":{},"所":{"docs":{},"求":{"docs":{},"的":{"docs":{},"也":{"docs":{},"是":{"docs":{},"多":{"docs":{},"维":{"docs":{},"的":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},"。":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}},";":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}},"}":{"docs":{},"}":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.019230769230769232}}}}}}},"y":{"docs":{},"(":{"docs":{},"w":{"docs":{},"*":{"docs":{},"x":{"docs":{},"+":{"docs":{},"b":{"docs":{},")":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}},",":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},")":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.015625}}}},"x":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}},"i":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"(":{"1":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"docs":{}}}}}},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"(":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"h":{"docs":{},"i":{"docs":{},"(":{"docs":{},"z":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}},"}":{"docs":{},")":{"docs":{},",":{"docs":{},"i":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}},"主":{"docs":{},"要":{"docs":{},"目":{"docs":{},"标":{"docs":{},"是":{"docs":{},"学":{"docs":{},"习":{"docs":{},"一":{"docs":{},"个":{"docs":{},"将":{"docs":{},"训":{"docs":{},"练":{"docs":{},"集":{"docs":{},"中":{"docs":{},"的":{"docs":{},"正":{"docs":{},"实":{"docs":{},"例":{"docs":{},"点":{"docs":{},"和":{"docs":{},"负":{"docs":{},"实":{"docs":{},"例":{"docs":{},"点":{"docs":{},"完":{"docs":{},"全":{"docs":{},"正":{"docs":{},"确":{"docs":{},"分":{"docs":{},"开":{"docs":{},"的":{"docs":{},"分":{"docs":{},"离":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},".":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"其":{"docs":{},"中":{"docs":{},"$":{"docs":{},"$":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"=":{"docs":{},"n":{"docs":{},"_":{"docs":{},"i":{"docs":{},"\\":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}},"则":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}},"逻":{"docs":{},"辑":{"docs":{},"回":{"docs":{},"归":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"为":{"docs":{},"：":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}},"学":{"docs":{},"习":{"docs":{},"策":{"docs":{},"略":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}},"算":{"docs":{},"法":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}},"对":{"docs":{},"于":{"docs":{},"误":{"docs":{},"分":{"docs":{},"类":{"docs":{},"的":{"docs":{},"点":{"docs":{},",":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}},"逻":{"docs":{},"辑":{"docs":{},"回":{"docs":{},"归":{"docs":{},":":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}},"偶":{"docs":{},"形":{"docs":{},"式":{"docs":{},"的":{"docs":{},"基":{"docs":{},"本":{"docs":{},"想":{"docs":{},"法":{"docs":{},"是":{"docs":{},"，":{"docs":{},"将":{"docs":{},"w":{"docs":{},"和":{"docs":{},"b":{"docs":{},"表":{"docs":{},"示":{"docs":{},"为":{"docs":{},"实":{"docs":{},"例":{"docs":{},"$":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"$":{"docs":{},"和":{"docs":{},"标":{"docs":{},"记":{"docs":{},"$":{"docs":{},"$":{"docs":{},"y":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"$":{"docs":{},"的":{"docs":{},"线":{"docs":{},"性":{"docs":{},"组":{"docs":{},"合":{"docs":{},"的":{"docs":{},"形":{"docs":{},"式":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"求":{"docs":{},"解":{"docs":{},"其":{"docs":{},"系":{"docs":{},"数":{"docs":{},"而":{"docs":{},"求":{"docs":{},"得":{"docs":{},"w":{"docs":{},"和":{"docs":{},"b":{"docs":{},".":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"误":{"docs":{},"分":{"docs":{},"类":{"docs":{},"点":{"docs":{},"到":{"docs":{},"分":{"docs":{},"离":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},"的":{"docs":{},"距":{"docs":{},"离":{"docs":{},"作":{"docs":{},"为":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},".":{"docs":{},"没":{"docs":{},"有":{"docs":{},"选":{"docs":{},"择":{"docs":{},"误":{"docs":{},"分":{"docs":{},"类":{"docs":{},"点":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"作":{"docs":{},"为":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"不":{"docs":{},"好":{"docs":{},"求":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"更":{"docs":{},"新":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"似":{"docs":{},"然":{"docs":{},"函":{"docs":{},"数":{"docs":{},"改":{"docs":{},"为":{"docs":{},"最":{"docs":{},"小":{"docs":{},"化":{"docs":{},"对":{"docs":{},"数":{"docs":{},"似":{"docs":{},"然":{"docs":{},"即":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"$":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"$":{"docs":{},".":{"docs":{},"(":{"docs":{},"其":{"docs":{},"实":{"docs":{},"就":{"docs":{},"是":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},")":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"总":{"docs":{},"结":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}},"感":{"docs":{},"知":{"docs":{},"机":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":5.0078125}},"(":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"c":{"docs":{},"e":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{},"是":{"docs":{},"最":{"docs":{},"基":{"docs":{},"础":{"docs":{},"的":{"docs":{},"线":{"docs":{},"性":{"docs":{},"二":{"docs":{},"分":{"docs":{},"类":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"输":{"docs":{},"入":{"docs":{},"实":{"docs":{},"例":{"docs":{},"的":{"docs":{},"特":{"docs":{},"征":{"docs":{},"向":{"docs":{},"量":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"实":{"docs":{},"例":{"docs":{},"的":{"docs":{},"$":{"docs":{},"$":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"m":{"docs":{},"$":{"docs":{},"$":{"docs":{},"类":{"docs":{},"别":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"学":{"docs":{},"习":{"docs":{},"算":{"docs":{},"法":{"docs":{},"就":{"docs":{},"是":{"docs":{},"对":{"docs":{},"以":{"docs":{},"下":{"docs":{},"最":{"docs":{},"优":{"docs":{},"化":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"算":{"docs":{},"法":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}},"是":{"docs":{},"误":{"docs":{},"分":{"docs":{},"类":{"docs":{},"驱":{"docs":{},"动":{"docs":{},"的":{"docs":{},"，":{"docs":{},"先":{"docs":{},"随":{"docs":{},"机":{"docs":{},"选":{"docs":{},"择":{"docs":{},"一":{"docs":{},"个":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},",":{"docs":{},"然":{"docs":{},"后":{"docs":{},"使":{"docs":{},"用":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"法":{"docs":{},"不":{"docs":{},"断":{"docs":{},"极":{"docs":{},"小":{"docs":{},"化":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},".":{"docs":{},"所":{"docs":{},"谓":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"法":{"docs":{},"就":{"docs":{},"是":{"docs":{},"使":{"docs":{},"用":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"不":{"docs":{},"断":{"docs":{},"更":{"docs":{},"新":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"对":{"docs":{},"偶":{"docs":{},"形":{"docs":{},"式":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}},"并":{"docs":{},"不":{"docs":{},"只":{"docs":{},"是":{"docs":{},"二":{"docs":{},"维":{"docs":{},"的":{"docs":{},"，":{"docs":{},"w":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}},"算":{"docs":{},"法":{"docs":{},"学":{"docs":{},"习":{"docs":{},"参":{"docs":{},"数":{"docs":{},"(":{"docs":{},"权":{"docs":{},"重":{"docs":{},"向":{"docs":{},"量":{"docs":{},"和":{"docs":{},"偏":{"docs":{},"置":{"docs":{},")":{"docs":{},"求":{"docs":{},"得":{"docs":{},"将":{"docs":{},"正":{"docs":{},"负":{"docs":{},"实":{"docs":{},"例":{"docs":{},"分":{"docs":{},"开":{"docs":{},"的":{"docs":{},"分":{"docs":{},"离":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},"。":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"利":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"误":{"docs":{},"分":{"docs":{},"类":{"docs":{},"点":{"docs":{},"到":{"docs":{},"分":{"docs":{},"离":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},"的":{"docs":{},"函":{"docs":{},"数":{"docs":{},"距":{"docs":{},"离":{"docs":{},"$":{"docs":{},"$":{"docs":{},"y":{"docs":{},"_":{"docs":{},"i":{"docs":{},"(":{"docs":{},"w":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"所":{"docs":{},"谓":{"docs":{},"对":{"docs":{},"偶":{"docs":{},"，":{"docs":{},"我":{"docs":{},"的":{"docs":{},"理":{"docs":{},"解":{"docs":{},"是":{"docs":{},"转":{"docs":{},"变":{"docs":{},"思":{"docs":{},"路":{"docs":{},"，":{"docs":{},"以":{"docs":{},"另":{"docs":{},"一":{"docs":{},"种":{"docs":{},"方":{"docs":{},"式":{"docs":{},"解":{"docs":{},"决":{"docs":{},"同":{"docs":{},"一":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"但":{"docs":{},"结":{"docs":{},"果":{"docs":{},"并":{"docs":{},"不":{"docs":{},"会":{"docs":{},"发":{"docs":{},"生":{"docs":{},"改":{"docs":{},"变":{"docs":{},"。":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"梯":{"docs":{},"度":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"每":{"docs":{},"个":{"docs":{},"变":{"docs":{},"量":{"docs":{},"的":{"docs":{},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{},"的":{"docs":{},"集":{"docs":{},"合":{"docs":{},"，":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"向":{"docs":{},"量":{"docs":{},"，":{"docs":{},"指":{"docs":{},"的":{"docs":{},"是":{"docs":{},"标":{"docs":{},"量":{"docs":{},"场":{"docs":{},"增":{"docs":{},"长":{"docs":{},"最":{"docs":{},"快":{"docs":{},"的":{"docs":{},"方":{"docs":{},"向":{"docs":{},"，":{"docs":{},"长":{"docs":{},"度":{"docs":{},"是":{"docs":{},"最":{"docs":{},"大":{"docs":{},"变":{"docs":{},"化":{"docs":{},"率":{"docs":{},"。":{"docs":{},"所":{"docs":{},"谓":{"docs":{},"标":{"docs":{},"量":{"docs":{},"场":{"docs":{},"，":{"docs":{},"指":{"docs":{},"的":{"docs":{},"是":{"docs":{},"空":{"docs":{},"间":{"docs":{},"中":{"docs":{},"任":{"docs":{},"意":{"docs":{},"一":{"docs":{},"个":{"docs":{},"点":{"docs":{},"的":{"docs":{},"属":{"docs":{},"性":{"docs":{},"都":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"一":{"docs":{},"个":{"docs":{},"标":{"docs":{},"量":{"docs":{},"表":{"docs":{},"示":{"docs":{},"的":{"docs":{},"场":{"docs":{},"。":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"以":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"回":{"docs":{},"归":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"本":{"docs":{},"质":{"docs":{},"是":{"docs":{},"：":{"docs":{},"输":{"docs":{},"出":{"docs":{},"y":{"docs":{},"=":{"1":{"docs":{},"的":{"docs":{},"对":{"docs":{},"数":{"docs":{},"几":{"docs":{},"率":{"docs":{},"是":{"docs":{},"输":{"docs":{},"入":{"docs":{},"x":{"docs":{},"的":{"docs":{},"线":{"docs":{},"性":{"docs":{},"函":{"docs":{},"数":{"docs":{},"表":{"docs":{},"示":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}},"概":{"docs":{},"念":{"docs":{},"与":{"docs":{},"定":{"docs":{},"义":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}},"用":{"docs":{},"来":{"docs":{},"判":{"docs":{},"断":{"docs":{},"是":{"docs":{},"否":{"docs":{},"训":{"docs":{},"练":{"docs":{},"完":{"docs":{},"成":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}},"算":{"docs":{},"法":{"docs":{},"实":{"docs":{},"现":{"docs":{},"(":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}},"效":{"docs":{},"果":{"docs":{},"可":{"docs":{},"视":{"docs":{},"化":{"docs":{},"：":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}},"的":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"性":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}},"输":{"docs":{},"入":{"docs":{},"空":{"docs":{},"间":{"docs":{},"$":{"docs":{},"$":{"docs":{},"r":{"docs":{},"^":{"docs":{},"{":{"docs":{},"n":{"docs":{},"}":{"docs":{},"$":{"docs":{},"$":{"docs":{},"中":{"docs":{},"任":{"docs":{},"一":{"docs":{},"点":{"docs":{},"$":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"0":{"docs":{},"$":{"docs":{},"$":{"docs":{},"到":{"docs":{},"超":{"docs":{},"平":{"docs":{},"面":{"docs":{},"s":{"docs":{},"的":{"docs":{},"距":{"docs":{},"离":{"docs":{},":":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"里":{"docs":{},"|":{"docs":{},"|":{"docs":{},"w":{"docs":{},"|":{"docs":{},"|":{"docs":{},"是":{"docs":{},"w":{"docs":{},"的":{"docs":{},"l":{"docs":{},"_":{"2":{"docs":{},"范":{"docs":{},"数":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}},"docs":{}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"最":{"docs":{},"大":{"docs":{},"似":{"docs":{},"然":{"docs":{},"法":{"docs":{},"进":{"docs":{},"行":{"docs":{},"参":{"docs":{},"数":{"docs":{},"估":{"docs":{},"计":{"docs":{},"，":{"docs":{},"学":{"docs":{},"习":{"docs":{},"使":{"docs":{},"得":{"docs":{},"当":{"docs":{},"前":{"docs":{},"标":{"docs":{},"记":{"docs":{},"序":{"docs":{},"列":{"docs":{},"出":{"docs":{},"现":{"docs":{},"概":{"docs":{},"率":{"docs":{},"最":{"docs":{},"大":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"向":{"docs":{},"量":{"docs":{},"$":{"docs":{},"w":{"docs":{},"$":{"docs":{},".":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"选":{"docs":{},"择":{"docs":{},"一":{"docs":{},"个":{"docs":{},"误":{"docs":{},"分":{"docs":{},"类":{"docs":{},"的":{"docs":{},"点":{"docs":{},"，":{"docs":{},"对":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{"Chapter1/1.1percetron.html":{"ref":"Chapter1/1.1percetron.html","tf":0.0078125}}}}}}}}}}}}}}}},":":{"docs":{},"=":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}},"e":{"docs":{},"^":{"docs":{},"{":{"docs":{},"w":{"docs":{},"\\":{"docs":{},"c":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.019230769230769232}}}}}}}}}}},"v":{"docs":{},"s":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}},"z":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},"=":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}},"{":{"1":{"docs":{},"}":{"docs":{},"{":{"1":{"docs":{},"+":{"docs":{},"e":{"docs":{},"^":{"docs":{},"{":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"docs":{}}}},"docs":{}},"}":{"docs":{},"}":{"docs":{},"$":{"docs":{},"$":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}},"{":{"1":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}},"docs":{}}}},"事":{"docs":{},"件":{"docs":{},"的":{"docs":{},"对":{"docs":{},"数":{"docs":{},"几":{"docs":{},"率":{"docs":{},"或":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"函":{"docs":{},"数":{"docs":{},"为":{"docs":{},"：":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"码":{"docs":{},"实":{"docs":{},"现":{"docs":{},"(":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{},":":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}},"似":{"docs":{},"然":{"docs":{},"函":{"docs":{},"数":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"几":{"docs":{},"率":{"docs":{},"(":{"docs":{},"o":{"docs":{},"d":{"docs":{},"d":{"docs":{},")":{"docs":{},":":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}},"参":{"docs":{},"数":{"docs":{},"学":{"docs":{},"习":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}},"更":{"docs":{},"新":{"docs":{},"：":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"指":{"docs":{},"事":{"docs":{},"件":{"docs":{},"发":{"docs":{},"生":{"docs":{},"的":{"docs":{},"概":{"docs":{},"率":{"docs":{},"与":{"docs":{},"该":{"docs":{},"事":{"docs":{},"件":{"docs":{},"不":{"docs":{},"发":{"docs":{},"生":{"docs":{},"的":{"docs":{},"概":{"docs":{},"率":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"比":{"docs":{},"值":{"docs":{},"。":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"法":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}},"每":{"docs":{},"次":{"docs":{},"更":{"docs":{},"新":{"docs":{},"参":{"docs":{},"数":{"docs":{},"使":{"docs":{},"用":{"docs":{},"全":{"docs":{},"部":{"docs":{},"样":{"docs":{},"本":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"更":{"docs":{},"新":{"docs":{},"幅":{"docs":{},"度":{"docs":{},"更":{"docs":{},"大":{"docs":{},"，":{"docs":{},"但":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"不":{"docs":{},"到":{"docs":{},"全":{"docs":{},"局":{"docs":{},"最":{"docs":{},"优":{"docs":{},"点":{"docs":{},"，":{"docs":{},"在":{"docs":{},"最":{"docs":{},"优":{"docs":{},"点":{"docs":{},"两":{"docs":{},"边":{"docs":{},"跳":{"docs":{},"动":{"docs":{},"，":{"docs":{},"而":{"docs":{},"且":{"docs":{},"如":{"docs":{},"果":{"docs":{},"样":{"docs":{},"本":{"docs":{},"数":{"docs":{},"量":{"docs":{},"太":{"docs":{},"大":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"太":{"docs":{},"大":{"docs":{},"；":{"docs":{},"每":{"docs":{},"次":{"docs":{},"更":{"docs":{},"新":{"docs":{},"参":{"docs":{},"数":{"docs":{},"使":{"docs":{},"用":{"docs":{},"一":{"docs":{},"个":{"docs":{},"样":{"docs":{},"本":{"docs":{},"的":{"docs":{},"随":{"docs":{},"机":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"频":{"docs":{},"率":{"docs":{},"更":{"docs":{},"快":{"docs":{},"，":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"得":{"docs":{},"也":{"docs":{},"更":{"docs":{},"快":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"跳":{"docs":{},"过":{"docs":{},"局":{"docs":{},"部":{"docs":{},"最":{"docs":{},"优":{"docs":{},"点":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"于":{"docs":{},"在":{"docs":{},"线":{"docs":{},"学":{"docs":{},"习":{"docs":{},"，":{"docs":{},"应":{"docs":{},"用":{"docs":{},"得":{"docs":{},"更":{"docs":{},"广":{"docs":{},"泛":{"docs":{},"；":{"docs":{},"还":{"docs":{},"有":{"docs":{},"一":{"docs":{},"种":{"docs":{},"改":{"docs":{},"进":{"docs":{},"的":{"docs":{},"随":{"docs":{},"机":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"是":{"docs":{},"每":{"docs":{},"次":{"docs":{},"随":{"docs":{},"机":{"docs":{},"选":{"docs":{},"取":{"docs":{},"更":{"docs":{},"新":{"docs":{},"参":{"docs":{},"数":{"docs":{},"用":{"docs":{},"的":{"docs":{},"样":{"docs":{},"本":{"docs":{},"。":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"牛":{"docs":{},"顿":{"docs":{},"法":{"docs":{},"：":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"线":{"docs":{},"性":{"docs":{},"回":{"docs":{},"归":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"设":{"docs":{},"$":{"docs":{},"$":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"h":{"docs":{},"i":{"docs":{},"(":{"docs":{},")":{"docs":{},"=":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{},",":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}},"逻":{"docs":{},"辑":{"docs":{},"回":{"docs":{},"归":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":5.009615384615385}},"是":{"docs":{},"使":{"docs":{},"用":{"docs":{},"线":{"docs":{},"性":{"docs":{},"预":{"docs":{},"测":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"去":{"docs":{},"逼":{"docs":{},"近":{"docs":{},"真":{"docs":{},"实":{"docs":{},"标":{"docs":{},"记":{"docs":{},"的":{"docs":{},"对":{"docs":{},"数":{"docs":{},"几":{"docs":{},"率":{"docs":{},"。":{"docs":{},"这":{"docs":{},"也":{"docs":{},"是":{"docs":{},"为":{"docs":{},"什":{"docs":{},"么":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{},"“":{"docs":{},"对":{"docs":{},"数":{"docs":{},"几":{"docs":{},"率":{"docs":{},"回":{"docs":{},"归":{"docs":{},"”":{"docs":{},"的":{"docs":{},"原":{"docs":{},"因":{"docs":{},"。":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"为":{"docs":{},":":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"学":{"docs":{},"习":{"docs":{},"通":{"docs":{},"常":{"docs":{},"采":{"docs":{},"用":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"法":{"docs":{},"和":{"docs":{},"拟":{"docs":{},"牛":{"docs":{},"顿":{"docs":{},"法":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"优":{"docs":{},"缺":{"docs":{},"点":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}},"参":{"docs":{},"数":{"docs":{},"估":{"docs":{},"计":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}},"定":{"docs":{},"义":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}},"本":{"docs":{},"质":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}},"相":{"docs":{},"当":{"docs":{},"于":{"docs":{},"线":{"docs":{},"性":{"docs":{},"预":{"docs":{},"测":{"docs":{},"结":{"docs":{},"果":{"docs":{},"经":{"docs":{},"过":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"类":{"docs":{},"别":{"docs":{},"概":{"docs":{},"率":{"docs":{},"分":{"docs":{},"布":{"docs":{},"。":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"Chapter1/1.2LogisticRegression.html":{"ref":"Chapter1/1.2LogisticRegression.html","tf":0.009615384615384616}}}}}}}}}}}}}},"length":196},"corpusTokens":["#","$$","$$\\nablawl(w,","$$b","$$l(w)","$$logit(p(y=1|x))","$$logit(p)","$$loss(\\phi(z),","$$min{w,b}","$$p(y=0|x)","$$p(y=1|x)","$$sigmoid","$$w","$$wj","$${\\nabla}{w}l(w,b)","$$其中","(1","(1):","(pred_i","(y^{(i)}","(z^{(i)}))^{1","(z^{(i)}))^{y^{(i)}}((1","({1,0})$$",")","*","+",",$$n_i$$表示当前实例更新的次数，实例点更新的次数越多，代表它离超平面越近，越难正确分类。","0,","1$$","1.1","1.2","1.2逻辑回归","1.3","1.3线性判别分析(linear","1])",":=","=","\\cdot","\\eta","\\frac","\\frac{1}{1","\\frac{e^{w\\cdot","\\frac{p(y=1|x)}{1","\\frac{p}{1","\\frac{w*x_0","\\leftarrow","\\phi","\\phi(z^{(i)})))$$","\\phi(z^{(i)}))x_j$$","\\prod_{i=1}^{n}((\\phi","\\rightarrow","\\subseteq","\\sum_{i=1}^n(","\\sum_{x_i\\subseteq","\\sum{i=1}^n","\\sum{i=1}^{n}a_iy_ix_i$$","\\sum{x_i","\\sum{x_i\\subseteq","a_i","analysis)","b","b)","b)=","b)}","b)​$$的总和，参数更新利用的是梯度下降。之所以是最基础是因为不管损失函数还是参数更新的方法都很是最简单的而且也没有对分离超平面进行限制取最优。感知机算法的对偶形式是将权重向量表示为实例ｘ和标记y的组合，使用了更多的矩阵运算，在使用相同的初始参数的情况下会得到相同的结果。","b}{||w||}","b求得对应的损失函数的极小值。损失函数的梯度为：","b进行更新","decis","def","e^{w\\cdot","flag","global","histori","introduct","l(w,","l(w,b","lda","log","logl(w)","lr):","m}y_i$$","m}y_ix_i$$","m}{y_i(w*x_i","np.asarray([0,","np.dot(w,","p(y=1|x)}","p(y|","pred_i","p}$$","range(len(x)):","regression）也称为\"对数几率回归\"，又称为\"逻辑斯谛\"回归。是一个对数线性分类模型，虽然有回归两个字，但属于分类模型而不是回归模型。","train(x,","true","vs","w","w)","w\\cdot","w_0,x_0","w_j","x","x$$","x;","x[i])","x^{(i)}$$","x_i","xiy_i","x}}$$","x可以是多维的权重向量和特征向量，一般都有多个特征，所求的也是多维的超平面。","y(w*x+b)","y)","y,","y[i])","y^{(i)})log(1","y^{(i)}log(\\phi(z^{(i)}))","y^{(i)}}),i","y_i$$","y_ix_i$$","yi","z^{(i)}=","{1}{1+e^{","}}$$","}}{1","个人机器学习笔记","主要目标是学习一个将训练集中的正实例点和负实例点完全正确分开的分离超平面.","事件的对数几率或logit函数为：","代码实现(python):","似然函数","其中$$a_i=n_i\\eta$$","几率(odd):","则","则逻辑回归的损失函数为：","参数学习","参数更新：","学习策略","学习算法","对于误分类的点,$$","对于逻辑回归:","对偶形式的基本想法是，将w和b表示为实例$$x_i$$和标记$$y_i$$的线性组合的形式，通过求解其系数而求得w和b.","将最大化似然函数改为最小化对数似然即损失函数$loss$.(其实就是cross_entropy)","将误分类点到分离超平面的距离作为损失函数.没有选择误分类点的数量作为损失函数，因为不好求梯度更新参数。","总结","感知机","感知机(perceptron)是最基础的线性二分类模型，输入实例的特征向量，输出实例的$$\\pm$$类别","感知机学习算法就是对以下最优化问题的算法","感知机学习算法是误分类驱动的，先随机选择一个超平面,然后使用梯度下降法不断极小化损失函数.所谓梯度下降法就是使用损失函数的梯度不断更新参数w","感知机学习算法的对偶形式","感知机并不只是二维的，w","感知机算法学习参数(权重向量和偏置)求得将正负实例分开的分离超平面。损失函数利用的是误分类点到分离超平面的函数距离$$y_i(w\\cdot","所以逻辑回归模型的本质是：输出y=1的对数几率是输入x的线性函数表示的模型。","所谓对偶，我的理解是转变思路，以另一种方式解决同一问题，但结果并不会发生改变。","所谓梯度，就是每个变量的偏导数的集合，是一个向量，指的是标量场增长最快的方向，长度是最大变化率。所谓标量场，指的是空间中任意一个点的属性都可以用一个标量表示的场。","指事件发生的概率与该事件不发生的概率之间的比值。","损失函数","梯度下降法","概念与定义","每次更新参数使用全部样本的梯度下降更新幅度更大，但可能会收敛不到全局最优点，在最优点两边跳动，而且如果样本数量太大消耗太大；每次更新参数使用一个样本的随机梯度下降更新的频率更快，收敛得也更快，也可以跳过局部最优点，可以用于在线学习，应用得更广泛；还有一种改进的随机梯度下降是每次随机选取更新参数用的样本。","牛顿法：","用来判断是否训练完成","第一章：线性分类模型","第七章：集成学习","第三章：神经网络","第九章：强化学习","第二章：决策树","第五章：贝叶斯分类器","第八章：无监督学习","第六章：图模型","第十一章：迁移学习","第十章：机器学习中的数学","第四章：支持向量机","算法实现(python)","算法效果可视化：","算法的收敛性","线性回归","设$$\\phi()=sigmoid,","输入空间$$r^{n}$$中任一点$$x_0$$到超平面s的距离:","这里||w||是w的l_2范数","这里使用最大似然法进行参数估计，学习使得当前标记序列出现概率最大的权重向量$w$.","选择一个误分类的点，对参数w","逻辑回归","逻辑回归是使用线性预测的结果去逼近真实标记的对数几率。这也是为什么被称为“对数几率回归”的原因。","逻辑回归模型为:","逻辑回归模型的参数学习通常采用的方法是梯度下降法和拟牛顿法","逻辑回归的优缺点","逻辑回归的参数估计","逻辑回归的定义","逻辑回归的本质","逻辑回归相当于线性预测结果经过sigmoid激活函数，得到类别概率分布。","逻辑回归（logist"],"pipeline":["stopWordFilter","stemmer"]},"store":{"./":{"url":"./","title":"Introduction","keywords":"","body":"个人机器学习笔记\n"},"Chapter1/1.MLAlgorithms.html":{"url":"Chapter1/1.MLAlgorithms.html","title":"第一章：线性分类模型","keywords":"","body":"第一章：线性分类模型\n"},"Chapter1/1.1percetron.html":{"url":"Chapter1/1.1percetron.html","title":"1.1 感知机","keywords":"","body":"1.1 感知机\n概念与定义\n感知机(Perceptron)是最基础的线性二分类模型，输入实例的特征向量，输出实例的$$\\pm$$类别\n主要目标是学习一个将训练集中的正实例点和负实例点完全正确分开的分离超平面.\n\n感知机并不只是二维的，w x可以是多维的权重向量和特征向量，一般都有多个特征，所求的也是多维的超平面。\n学习策略\n将误分类点到分离超平面的距离作为损失函数.没有选择误分类点的数量作为损失函数，因为不好求梯度更新参数。                                                                 \n输入空间$$R^{n}$$中任一点$$x_0$$到超平面S的距离:\n$$ \\frac{w*x_0 + b}{||w||} $$\n$$ 这里||w||是w的L_2范数 $$\n对于误分类的点,$$ y(w*x+b) \n则 损失函数 $$ L(w, b)= - \\sum_{x_i\\subseteq M}{y_i(w*x_i + b)} $$\n学习算法\n感知机学习算法就是对以下最优化问题的算法\n$$min{w,b} L(w,b ) =- \\sum{x_i\\subseteq M}{y_i(w*x_i + b)} $$\n感知机学习算法是误分类驱动的，先随机选择一个超平面,然后使用梯度下降法不断极小化损失函数.所谓梯度下降法就是使用损失函数的梯度不断更新参数w b求得对应的损失函数的极小值。损失函数的梯度为：\n$${\\nabla}{w}L(w,b) = -\\sum{x_i \\subseteq M}y_ix_i$$\n$$\\nablawL(w, b) = -\\sum{x_i\\subseteq M}y_i$$\n所谓梯度，就是每个变量的偏导数的集合，是一个向量，指的是标量场增长最快的方向，长度是最大变化率。所谓标量场，指的是空间中任意一个点的属性都可以用一个标量表示的场。\n选择一个误分类的点，对参数w b进行更新\n$$w \\leftarrow w + \\eta y_ix_i$$          \n$$b  \\leftarrow b + \\eta y_i$$\n\n算法实现(Python)\ndef train(x, y, lr):\n    w = np.asarray([0, 0, 1])\n    global  history\n    while (1):\n        flag = True # 用来判断是否训练完成\n        for i in range(len(x)):\n            pred_y = np.dot(w, x[i])\n            if (pred_y * y[i]) \n算法效果可视化：\n\n算法的收敛性\n\n感知机学习算法的对偶形式\n所谓对偶，我的理解是转变思路，以另一种方式解决同一问题，但结果并不会发生改变。\n对偶形式的基本想法是，将w和b表示为实例$$x_i$$和标记$$y_i$$的线性组合的形式，通过求解其系数而求得w和b.\n$$w = w + \\eta xiy_i  \\rightarrow w = \\sum{i=1}^{N}a_iy_ix_i$$\n$$b = b + \\eta yi  \\rightarrow   b = \\sum{i=1}^N a_i y_i$$\n其中$$a_i=n_i\\eta$$ ,$$n_i$$表示当前实例更新的次数，实例点更新的次数越多，代表它离超平面越近，越难正确分类。\n\n总结\n感知机算法学习参数(权重向量和偏置)求得将正负实例分开的分离超平面。损失函数利用的是误分类点到分离超平面的函数距离$$y_i(w\\cdot x_i + b)​$$的总和，参数更新利用的是梯度下降。之所以是最基础是因为不管损失函数还是参数更新的方法都很是最简单的而且也没有对分离超平面进行限制取最优。感知机算法的对偶形式是将权重向量表示为实例ｘ和标记y的组合，使用了更多的矩阵运算，在使用相同的初始参数的情况下会得到相同的结果。\n"},"Chapter1/1.2LogisticRegression.html":{"url":"Chapter1/1.2LogisticRegression.html","title":"1.2 逻辑回归","keywords":"","body":"1.2逻辑回归\n逻辑回归的定义\n逻辑回归（Logistic Regression）也称为\"对数几率回归\"，又称为\"逻辑斯谛\"回归。是一个对数线性分类模型，虽然有回归两个字，但属于分类模型而不是回归模型。\n逻辑回归模型为:\n$$P(Y=1|x) = \\frac{e^{w\\cdot x }}{1 + e^{w\\cdot x}}$$\n$$P(Y=0|x) = \\frac{1}{1 + e^{w\\cdot x }}$$\n$$其中 b = w_0,x_0 = 1$$\n逻辑回归的本质\n几率(odd): 指事件发生的概率与该事件不发生的概率之间的比值。\n事件的对数几率或logit函数为：\n$$logit(p) = log \\frac{p}{1-p}$$\n对于逻辑回归:\n $$logit(P(Y=1|x)) = log \\frac{P(Y=1|x)}{1-P(Y=1|x)} = w\\cdot x$$\n所以逻辑回归模型的本质是：输出Y=1的对数几率是输入x的线性函数表示的模型。 逻辑回归是使用线性预测的结果去逼近真实标记的对数几率。这也是为什么被称为“对数几率回归”的原因。\n逻辑回归的参数估计\n逻辑回归相当于线性预测结果经过sigmoid激活函数，得到类别概率分布。\n$$sigmoid = \\frac {1}{1+e^{-x}}$$\n这里使用最大似然法进行参数估计，学习使得当前标记序列出现概率最大的权重向量$W$.\n似然函数\n设$$\\phi()=sigmoid, z^{(i)}= w \\cdot x^{(i)}$$\n$$L(w) = P(y| x; w) = \\prod_{i=1}^{n}((\\phi (z^{(i)}))^{y^{(i)}}((1-\\phi (z^{(i)}))^{1-y^{(i)}}),y \\subseteq ({1,0})$$\n则逻辑回归的损失函数为：\n$$Loss(\\phi(z), y) = - logL(w) = \\sum_{i=1}^n(- y^{(i)}log(\\phi(z^{(i)}))-(1-y^{(i)})log(1-\\phi(z^{(i)})))$$\n将最大化似然函数改为最小化对数似然即损失函数$Loss$.(其实就是Cross_Entropy)\n参数学习\n逻辑回归模型的参数学习通常采用的方法是梯度下降法和拟牛顿法\n梯度下降法\n参数更新：\n$$wj := w_j + \\eta \\sum{i=1}^n (y^{(i)}-\\phi(z^{(i)}))x_j$$\n代码实现(Python):\n每次更新参数使用全部样本的梯度下降更新幅度更大，但可能会收敛不到全局最优点，在最优点两边跳动，而且如果样本数量太大消耗太大；每次更新参数使用一个样本的随机梯度下降更新的频率更快，收敛得也更快，也可以跳过局部最优点，可以用于在线学习，应用得更广泛；还有一种改进的随机梯度下降是每次随机选取更新参数用的样本。\n牛顿法：\n逻辑回归的优缺点\n逻辑回归 vs 线性回归\n"},"Chapter1/1.3LDA.html":{"url":"Chapter1/1.3LDA.html","title":"1.3 LDA","keywords":"","body":"1.3线性判别分析(Linear Decision Analysis)\n"},"Chpater2/2.DicisionTree.html":{"url":"Chpater2/2.DicisionTree.html","title":"第二章：决策树","keywords":"","body":"第二章：决策树\n"},"Chpater3/3.NeuralNetwork.html":{"url":"Chpater3/3.NeuralNetwork.html","title":"第三章：神经网络","keywords":"","body":"第三章：神经网络\n"},"Chpater4/4.SVM.html":{"url":"Chpater4/4.SVM.html","title":"第四章：支持向量机","keywords":"","body":"第四章：支持向量机\n"},"Chpater5/5.Bayes.html":{"url":"Chpater5/5.Bayes.html","title":"第五章：贝叶斯分类器","keywords":"","body":"第五章：贝叶斯分类器\n"},"Chpater6/6.GraphModel.html":{"url":"Chpater6/6.GraphModel.html","title":"第六章：图模型","keywords":"","body":"第六章：图模型\n"},"Chpater7/7.EmsembleLearning.html":{"url":"Chpater7/7.EmsembleLearning.html","title":"第七章：集成学习","keywords":"","body":"第七章：集成学习\n"},"Chpater8/8.UnsupervisedLearning.html":{"url":"Chpater8/8.UnsupervisedLearning.html","title":"第八章：无监督学习","keywords":"","body":"第八章：无监督学习\n"},"Chpater8/8.EnhancementLearning.html":{"url":"Chpater8/8.EnhancementLearning.html","title":"第九章：强化学习","keywords":"","body":"第九章：强化学习\n"},"Chpater10/10.MathofML.html":{"url":"Chpater10/10.MathofML.html","title":"第十章：机器学习中的数学","keywords":"","body":"第十章：机器学习中的数学\n"},"Chpater11/11.TransferLearning.html":{"url":"Chpater11/11.TransferLearning.html","title":"第十一章：迁移学习","keywords":"","body":"第十一章：迁移学习\n"}}}