# 4.2对偶问题

### 线性可分支持向量机的对偶形式

![png](./pngs/10.png)*(4.7)*

上式是一个凸二次规划问题， 可以使⽤拉格朗⽇乘⼦法得到其的“对偶问题”(dual problem)，即对公式每个约束添加拉格朗日乘子 $$\alpha_i >= 0$$， 定义拉格朗日函数:

![png](./pngs/11.png)*(4.8)*

根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：

![png](./pngs/16.png)*(4.9)*

(1) 求$$min_{w, b}(w, b, \alpha)$$

令$$L(\omega, b, \alpha)$$ 对 $$\omega$$ 和 $$b$$ 的偏导为0可得：

![png](./pngs/12.png)*(4.10)*

将式(4.9)带入(4.8)，可以将 $$\omega$$ 和 $$b$$ 消去，就可以得到(4.7)的对偶问题：

![png](./pngs/13.png)*(4.11)*

(2) 求$$min_{w, b} L(w, b, \alpha)$$ 对 $$\alpha$$ 的极大，即是对偶问题

![png](./pngs/14.png)*（4.12）

将式(4.12)的目标函数由极大转换成求极小，就得到下面与之等价的对偶最优化问题：

![png](./pngs/15.png)*（4.13）*

求解原始问题(4.7)可以转换为求解对偶问题(4.13).

对线性可分训练数据集，假设对偶最优化问题对 $$\alpha$$ 的解为 $$\alpha^* = (\alpha_1^*, \alpha_1^*,..., \alpha^*_N)$$，可以由 $\alpha^*$ 求得原始最优化问题对 $$(w, b)$$的解$$(w^*, b^*)$$.

![png](./pngs/17.png)*(4.14)*

![png](./pngs/18.png)*(4.15)*

这就是说，**分类决策函数只依赖于输入x和训练样本输入的内积.**式(4.15)成为线性可分支持向量机学习的基本算法。

> 每个实例都有其对应$$\alpha_i$$,有$$\alpha_i(y_i(wx_i+b)-1) = 0$$知，如果$$\alpha_i$$不为0，那么$$y_i(wx_i+b)= 1$$，即该实例为支持向量，所以支持向量机最终的模型只与支持向量有关，这也是这个算法被称为支持向量机的原因。分类决策函数因为非支持向量对应的$$\alpha_i$$为0，相当于也只依赖于支持向量。



### 线性可分支持向量机学习算法

![png](./pngs/19.png)

![png](./pngs/20.png) 


###  算法求解实例

![png](./pngs/21.png)

![png](./pngs/22.png)  

![png](./pngs/23.png)

