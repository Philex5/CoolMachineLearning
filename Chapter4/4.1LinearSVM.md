 4.1线性支持向量机

## 线性二分类模型

给定一组数据$$ {(x_1,y_1),(x_2,y_2),...,(x_m,y_m)} $$, 其 中 $$xi ∈R^d,y ∈ \lbrace −1,1 \rbrace, $$二分类任务的目标是希望从数据中学得一个假设函数 h: $$R →  \lbrace −1,1 \rbrace$$, 使得 $$h(x_i) = y_i $$, 即

![png](./pngs/1.png)

用一个更简洁的形式表示是：

![png](./pngs/2.png)

其中 $$w_i \in R^d, b \in R.$$

> ![png](./pngs/3.png)



## 线性支持向量机

线性支持向量机 (SVM) 也是一种线性二分类模 型, 也需要找到满足*定理1*约束的划分超平面, 即 (w,b). 由于能将样本分开的超平面可能有很多, SVM 进一步希望找到离各样本都比较远的划分超平面. 这样的超平面在面对距离较近的样本点的时候也能有比较好的分类性能，且能接受样本点的一些误差和扰动，不至于让样本点直接穿越到超平面的另一边；除此之外，由于样本的局限性或噪声的因素，训练集外的样本可能更接近两个类的分割界，SVM得到的划分超平面受影响最小，产生的分类结果是最鲁棒的，对未见示例的泛化能力最强。

### 间隔与支持向量

在样本空间中，划分超平面可通过如下线性方程来描述：

![png](./pngs/4.png)

样本空间中任⼀点 x，到超平⾯ (w,b) 的距离可以写为： 

![png](./pngs/5.png)

假设超平⾯ $$(w,b) $$能使训练样本正确分类，即对于$$ (x_i,y_i) ∈ D$$，有:

  ![png](./pngs/6.png)    

对于距离超平⾯最近的⼏个点使得上式的等号成⽴，那么它们被称为“⽀持 向量 (support vector)”，如下图所⽰，两个异类⽀持向量到超平⾯的距离之和为

![png](./pngs/7.png)

几何距离与支持向量如图所示：

![png](./pngs/8.png)

> 支持向量的函数值为什么等于1和-1？
>
> 解释见[《统计学习方法》“支持向量机”一章中说可以取函数间隔等于 1 是为什么？](https://blog.csdn.net/lw_power/article/details/82940105)

欲找到最⼤间隔 (maximum margin) 来划分超平⾯，也就是要找到能满⾜约束的 w,b，使得 γ最⼤，即：

![png](./pngs/9.png)

即只需要最大化$$ \frac{1}{||w||}，即最小化||w||^2$$即可，所以将上式改写为：

![png](./pngs/10.png)

这个就是**⽀持向量机 (Support Vector Machine,SVM) 的基本型.**

