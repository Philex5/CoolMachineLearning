# 4.5优化方法

## 1. 序列最小最优化算法(sequential minimal optimization，SMO)

支持向量机的学习问题可以形式化为凸二次规划问题。这样的凸二次规划问题具有全局最优解，并且有许多最优化算法可以用于这一问题的求解。但是当训练样本容量很大时，这些算法往往变得非常低效，以致无法使用。所以**如何高效地实现支持向量机学习**成为一个重要的问题。这里介绍实现这一目标的SMO算法。

> 待补充



## 2. Pegasos

我们也可以直接在原问题对支持向量机进行优化, 尤其是使用线性核函数时, 我们有很高效的优化算法, 如 Pegasos . Pegasos 使用基于梯度的方法在线性支持向量机基本型进行优化, 

![](./pngs/43.png)

算法流程如下图：

![](./pngs/42.png)

## 3. 近似算法

当使用非线性核函数下的支持向量机时, 由于核 矩阵 $$K := [κ(x_i,x_j)]_{m×m}$$, 所以时间复杂度一定是 Ω(m2). 因此, 有许多学者致力于研究一些快速的近 似算法. 例如, CVM 基于近似最小包围球算法, Nyström 方法 通过从 K 采样出一些列来得到 K 的低秩近似, 随机傅里叶特征 [12]构造了向低维空间的 随机映射. 

